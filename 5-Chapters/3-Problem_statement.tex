%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% PROBLEM FORMULATION OR STATEMENT %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\chapter{Problem Statement}\label{chap:Problem_statement}

\section{Fusion Algorithm}\label{sec:2-bayes_fusion}
Fusing measurements from two heterogeneous sensors that have few cross-correlations can be challenging. 
To take inputs from two different sensors and give them weight, we use Bayes Fusion in this thesis.
Bayes fusion takes the noises of both sensors to determine their reliability at a given point of the measurement.
Thus giving us a reliable way to give scores of trust to each sensor.

The coordinates that undergo fusion from both radar and image sensors are the horizontal coordinates,
specifically the radar's azimuth and the image's "u" coordinate. 
This constraint arises from the fact that these are the only coordinates where both sensors provide measurements, 
as illustrated in Figure \ref{fig:trade_off_and_plane}\subref{subfig:cam_radar_sub}.
It's important to note that radar's elevation measurement resolution is limited and subject to noise. 
Additionally, the image sensor does not provide depth information.

If X is the real position of the object, 
then Bayes' theorem predicts that the probability of the fused position is shown in equation \ref{equ:bayes1} \cite{10.1007/978-981-16-2248-9_32}.

\begin{equation}\label{equ:bayes1}
    P_{prob}(\frac{P}{X})=
    \frac
    {e \frac{−(P−X)^T R^{−1}(P−X)}{2}}
    {2 \pi R^(0.5)}
\end{equation}

Applying Bayes' fusion, the value of the measured measurements is provided by equation \ref{equ:bayes2}.

\begingroup
\large
\begin{equation}\label{equ:bayes2}
P_{x_{bayes}}=\frac
{\frac{p_{x_{radar}}}{R_{radar}}+\frac{p_{x_{cam}}} {R_{cam}}}
{\frac{1}{R_{radar}}+\frac{1}{R_{cam}}}
\end{equation}
\endgroup

where
\begin{align*}
    P_{x_{bayes}} &= \text{fused position}\\
    p_{x_{radar}} &= \text{radar x-axis in cartesian}\\
    p_{x_{cam}} &= \text{camera x-axis in cartesian}\\
    R_{radar} &= \text{radar covariance}\\
    R_{cam} &= \text{camera covariance}
\end{align*}
\begin{equation}\label{equ:bayes4}
    \frac{1}{R}=\frac{1}{R_1}+\frac{1}{R_2}
\end{equation}
\begin{equation}\label{equ:2-radar_R}
    \mathbf{R}_{radar} = 
        \sigma_{radar_x}^2 
\end{equation}
\begin{equation}\label{equ:2-R_cam}
    \mathbf{R}_{cam} = 
        \sigma_{cam_u}^2
\end{equation}


\section{Motion Model}\label{sec:2-kalman_filter}
%To predict the movement model of our subjects, we use a Constant Acceleration model of Kalman filter.

\subsection{Predict}\label{sec:2-predict}
The state matrix used in this Kalman Filter is from the single sensor maneuvering tracking, with constant velocity.
It has four elements and is defined with position and velocity, which projects onto the x-axis and y-axis:

\begin{equation}\label{equ:state_eq}
    \mathbf{x} = 
        \begin{bmatrix} 
        p \\ 
        v 
        \end{bmatrix} = 
        \begin{bmatrix} 
        p_x \\ 
        p_y \\ 
        v_x \\ 
        v_y 
        \end{bmatrix}
\end{equation}
where
\begin{align*}
    p_x &=\text{position x}\\
    p_y &=\text{position y}\\
    v_x &=\text{velocity x}\\
    v_y &=\text{velocity y}\\
\end{align*}

\begin{equation}\label{equ:transition_matrix_H}
    \mathbf{F} = 
    \begin{bmatrix}
        1 & 0 & 1 & 0 \\
        0 & 1 & 0 & 1 \\
        0 & 0 & 0 & 0 \\
        0 & 0 & 0 & 0 \\
      \end{bmatrix}
\end{equation}

\begin{equation}\label{equ:predict_eq}
    \mathbf{x}_k=\mathbf{F}_k\mathbf{x}_{k-1}+\mathbf{w}
\end{equation}

Error covariance update
\begin{equation}\label{equ:error_covariance}
    \mathbf{P}_k=\mathbf{F}_k \mathbf{P}_{k-1} \mathbf{F}_k^T+\mathbf{Q}_k
\end{equation}

\subsection{Update}\label{equ:2_update}
To fuse two sensors with different update rates, Kalman Filter is updated seperately (figure \ref{fig:sync_fig}).
Updates are based on the fps of each sensor.
\begin{figure}[hpbt]
    \centering
    \includegraphics[width=\textwidth]{Figures/sync.png}%\textwidth
    \caption{Update timing \cite{7472511}}
    \label{fig:sync_fig}
\end{figure}

\subsubsection{Radar Update}\label{sec:2-radar_update}  
Centroid of radar
\begin{equation}
    \mathbf{z}_{radar}=
    \begin{bmatrix}
        P_{x_{bayes}} \\ 
        p_y
    \end{bmatrix}
\end{equation}
\begin{equation}\label{equ:2_radar_R_kf}
    \mathbf{R}_{radar} = 
    \begin{bmatrix}
        \sigma_{radar_x}^2 & 0 \\
        0 & \sigma_{radar_y}^2 \\
      \end{bmatrix}
\end{equation}
Transition matrix
\begin{equation}\label{equ:2_radar_transition_matrix}
    \mathbf{H} = 
    \begin{bmatrix}
        1 & 0 & 0 & 0 \\
        0 & 1 & 0 & 0 \\
      \end{bmatrix}
\end{equation}



\subsubsection{Camera Update}\label{sec:2-camera_update}
The camera's state measurements update follows the same procedure that of radar.
\begin{equation}\label{equ:2_z_cam}
    \mathbf{z}_{cam}=
    \begin{bmatrix}P_{x_{bayes}}\end{bmatrix}
\end{equation}

\begin{equation}\label{equ:2_cam_transition_matrix}
    \mathbf{H} = 
    \begin{bmatrix}
        1 & 0 & 0 & 0 \\
      \end{bmatrix}
\end{equation}